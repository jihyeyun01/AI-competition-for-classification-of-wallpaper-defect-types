{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alstn\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':3,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE': 256,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "size = print(EfficientNet.get_image_size(\"efficientnet-b2\"))\n",
    "size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.getcwd()\n",
    "\n",
    "img_folder = glob.glob(img_dir + '\\\\train\\\\*')\n",
    "\n",
    "all_img_list = []\n",
    "\n",
    "for folder in img_folder:\n",
    "    imgs = glob.glob(folder + '\\\\*')\n",
    "    all_img_list += imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\0.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\11.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\2.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\s\\995.png</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\s\\996.png</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\s\\997.png</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\s\\998.png</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\s\\999.png</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path label\n",
       "0       c:\\Programing\\competition\\Dobae\\train\\a\\0.png     a\n",
       "1       c:\\Programing\\competition\\Dobae\\train\\a\\1.png     a\n",
       "2      c:\\Programing\\competition\\Dobae\\train\\a\\10.png     a\n",
       "3      c:\\Programing\\competition\\Dobae\\train\\a\\11.png     a\n",
       "4       c:\\Programing\\competition\\Dobae\\train\\a\\2.png     a\n",
       "...                                               ...   ...\n",
       "3452  c:\\Programing\\competition\\Dobae\\train\\s\\995.png     s\n",
       "3453  c:\\Programing\\competition\\Dobae\\train\\s\\996.png     s\n",
       "3454  c:\\Programing\\competition\\Dobae\\train\\s\\997.png     s\n",
       "3455  c:\\Programing\\competition\\Dobae\\train\\s\\998.png     s\n",
       "3456  c:\\Programing\\competition\\Dobae\\train\\s\\999.png     s\n",
       "\n",
       "[3457 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[-2])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\0.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\11.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\2.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\50.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\6.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\7.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\8.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\9.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0      c:\\Programing\\competition\\Dobae\\train\\a\\0.png     a\n",
       "1      c:\\Programing\\competition\\Dobae\\train\\a\\1.png     a\n",
       "2     c:\\Programing\\competition\\Dobae\\train\\a\\10.png     a\n",
       "3     c:\\Programing\\competition\\Dobae\\train\\a\\11.png     a\n",
       "4      c:\\Programing\\competition\\Dobae\\train\\a\\2.png     a\n",
       "...                                              ...   ...\n",
       "2047  c:\\Programing\\competition\\Dobae\\train\\r\\50.png     r\n",
       "2048   c:\\Programing\\competition\\Dobae\\train\\r\\6.png     r\n",
       "2049   c:\\Programing\\competition\\Dobae\\train\\r\\7.png     r\n",
       "2050   c:\\Programing\\competition\\Dobae\\train\\r\\8.png     r\n",
       "2051   c:\\Programing\\competition\\Dobae\\train\\r\\9.png     r\n",
       "\n",
       "[810 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotate 훼손, 오염, 걸베받이수정, 꼬임, 몰딩수정\n",
    "df_1 = df.copy()\n",
    "drop_idx = df_1[(df_1['label'] == 's') | (df_1['label'] == 'k') | (df_1['label'] == 'b') | (df_1['label'] == 'd') | (df_1['label'] == 'h')].index\n",
    "df_1.drop(drop_idx, inplace = True)\n",
    "df_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\0.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\11.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\2.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\50.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\6.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\7.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\8.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\9.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "0      c:\\Programing\\competition\\Dobae\\train\\a\\0.png     a\n",
       "1      c:\\Programing\\competition\\Dobae\\train\\a\\1.png     a\n",
       "2     c:\\Programing\\competition\\Dobae\\train\\a\\10.png     a\n",
       "3     c:\\Programing\\competition\\Dobae\\train\\a\\11.png     a\n",
       "4      c:\\Programing\\competition\\Dobae\\train\\a\\2.png     a\n",
       "...                                              ...   ...\n",
       "2047  c:\\Programing\\competition\\Dobae\\train\\r\\50.png     r\n",
       "2048   c:\\Programing\\competition\\Dobae\\train\\r\\6.png     r\n",
       "2049   c:\\Programing\\competition\\Dobae\\train\\r\\7.png     r\n",
       "2050   c:\\Programing\\competition\\Dobae\\train\\r\\8.png     r\n",
       "2051   c:\\Programing\\competition\\Dobae\\train\\r\\9.png     r\n",
       "\n",
       "[1457 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df.copy()\n",
    "drop_idx = df_0[(df_0['label'] == 's') | (df_0['label'] == 'k')].index\n",
    "df_0.drop(drop_idx, inplace = True)\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\0.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\1.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\10.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\11.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\a\\2.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\q\\0.png</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\q\\1.png</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\q\\2.png</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\q\\3.png</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\q\\4.png</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          img_path label\n",
       "0    c:\\Programing\\competition\\Dobae\\train\\a\\0.png     a\n",
       "1    c:\\Programing\\competition\\Dobae\\train\\a\\1.png     a\n",
       "2   c:\\Programing\\competition\\Dobae\\train\\a\\10.png     a\n",
       "3   c:\\Programing\\competition\\Dobae\\train\\a\\11.png     a\n",
       "4    c:\\Programing\\competition\\Dobae\\train\\a\\2.png     a\n",
       "..                                             ...   ...\n",
       "95   c:\\Programing\\competition\\Dobae\\train\\q\\0.png     q\n",
       "96   c:\\Programing\\competition\\Dobae\\train\\q\\1.png     q\n",
       "97   c:\\Programing\\competition\\Dobae\\train\\q\\2.png     q\n",
       "98   c:\\Programing\\competition\\Dobae\\train\\q\\3.png     q\n",
       "99   c:\\Programing\\competition\\Dobae\\train\\q\\4.png     q\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반점 i 틈새과다 q 가구수정 a 녹오염 e 이음부불량 n 창틀문틀수정 o 울음 m\n",
    "# | (df_2['label'] == 'm')\n",
    "df_2 = df.copy()\n",
    "df_2 = df_2[(df_2['label'] == 'i') | (df_2['label'] == 'q') | (df_2['label'] == 'a') | (df_2['label'] == 'e') | (df_2['label'] == 'n') | (df_2['label'] == 'o') | (df_2['label'] == 'm')]\n",
    "df_2 = df_2.reset_index(drop=True)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'],\n",
    "                                    test_size=0.5,\n",
    "                                    stratify=df['label'],\n",
    "                                    random_state = CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "s    702\n",
       "k    297\n",
       "b    153\n",
       "d    105\n",
       "p     81\n",
       "c     72\n",
       "l     71\n",
       "h     65\n",
       "g     49\n",
       "j     28\n",
       "f     27\n",
       "r     26\n",
       "o     14\n",
       "m     11\n",
       "n      9\n",
       "e      7\n",
       "a      6\n",
       "q      3\n",
       "i      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "s    703\n",
       "k    298\n",
       "b    154\n",
       "d    105\n",
       "p     81\n",
       "c     73\n",
       "l     71\n",
       "h     65\n",
       "g     50\n",
       "j     29\n",
       "f     27\n",
       "r     25\n",
       "o     13\n",
       "m     11\n",
       "n      8\n",
       "e      7\n",
       "a      6\n",
       "q      2\n",
       "i      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = train.copy()\n",
    "df_3 = df_3[(df_3['label'] == 'i') | (df_3['label'] == 'q') | (df_3['label'] == 'a') | (df_3['label'] == 'e') | (df_3['label'] == 'n') | (df_3['label'] == 'o') | (df_3['label'] == 'm')]\n",
    "df_3 = df_3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\j\\44.png</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\37.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\n\\12.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\o\\9.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\m\\15.png</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\n\\11.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\f\\7.png</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\1.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\f\\18.png</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\j\\18.png</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path label\n",
       "1013  c:\\Programing\\competition\\Dobae\\train\\j\\44.png     j\n",
       "2032  c:\\Programing\\competition\\Dobae\\train\\r\\37.png     r\n",
       "1794  c:\\Programing\\competition\\Dobae\\train\\n\\12.png     n\n",
       "1833   c:\\Programing\\competition\\Dobae\\train\\o\\9.png     o\n",
       "1775  c:\\Programing\\competition\\Dobae\\train\\m\\15.png     m\n",
       "...                                              ...   ...\n",
       "1793  c:\\Programing\\competition\\Dobae\\train\\n\\11.png     n\n",
       "739    c:\\Programing\\competition\\Dobae\\train\\f\\7.png     f\n",
       "2002   c:\\Programing\\competition\\Dobae\\train\\r\\1.png     r\n",
       "698   c:\\Programing\\competition\\Dobae\\train\\f\\18.png     f\n",
       "984   c:\\Programing\\competition\\Dobae\\train\\j\\18.png     j\n",
       "\n",
       "[133 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4= train.copy()\n",
    "drop_idx = df_4[(df_4['label'] == 's') | (df_4['label'] == 'k') | (df_4['label'] == 'b') | (df_4['label'] == 'd') | (df_4['label'] == 'p') | (df_4['label'] == 'l') | (df_4['label'] == 'c') | (df_4['label'] == 'g') | (df_4['label'] == 'h') ].index\n",
    "df_4.drop(drop_idx, inplace = True)\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\h\\83.png</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\p\\159.png</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\j\\44.png</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\l\\82.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\37.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\p\\18.png</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\r\\1.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\f\\18.png</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\c\\2.png</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>c:\\Programing\\competition\\Dobae\\train\\j\\18.png</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_path label\n",
       "953    c:\\Programing\\competition\\Dobae\\train\\h\\83.png     h\n",
       "1901  c:\\Programing\\competition\\Dobae\\train\\p\\159.png     p\n",
       "1013   c:\\Programing\\competition\\Dobae\\train\\j\\44.png     j\n",
       "1749   c:\\Programing\\competition\\Dobae\\train\\l\\82.png     l\n",
       "2032   c:\\Programing\\competition\\Dobae\\train\\r\\37.png     r\n",
       "...                                               ...   ...\n",
       "1906   c:\\Programing\\competition\\Dobae\\train\\p\\18.png     p\n",
       "2002    c:\\Programing\\competition\\Dobae\\train\\r\\1.png     r\n",
       "698    c:\\Programing\\competition\\Dobae\\train\\f\\18.png     f\n",
       "376     c:\\Programing\\competition\\Dobae\\train\\c\\2.png     c\n",
       "984    c:\\Programing\\competition\\Dobae\\train\\j\\18.png     j\n",
       "\n",
       "[729 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5 = train.copy()\n",
    "drop_idx = df_5[(df_5['label'] == 's') | (df_5['label'] == 'k')].index\n",
    "df_5.drop(drop_idx, inplace = True)\n",
    "df_5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
      " 's']\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df_0['label'] = le.fit_transform(df_0['label'])\n",
    "df_1['label'] = le.fit_transform(df_1['label'])\n",
    "df_2['label'] = le.fit_transform(df_2['label'])\n",
    "df_3['label'] = le.fit_transform(df_3['label'])\n",
    "df_4['label'] = le.fit_transform(df_4['label'])\n",
    "df_5['label'] = le.fit_transform(df_5['label'])\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cgan , smote, adasyn, b smote, gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        # image = cv2.imread(img_path)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.open(img_path)\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transform = A.Compose([\n",
    "                            A.Resize(224,224),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dataset = CustomDataset(train['img_path'].values, train['label'].values, mean_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanstd_loader = DataLoader(mean_dataset, batch_size = 32, num_workers=0)\n",
    "\n",
    "\n",
    "print('==> Computing mean and std..')\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "\n",
    "for inputs, _labels in meanstd_loader:\n",
    "    for i in range(3):\n",
    "        mean[i] += inputs[:,i,:,:].mean()\n",
    "        std[i] += inputs[:,i,:,:].std()\n",
    "mean.div_(len(meanstd_loader))\n",
    "std.div_(len(meanstd_loader))\n",
    "print(mean, std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            A.HorizontalFlip(p = 1),\n",
    "                            A.RandomBrightness(p = 1),\n",
    "                            A.GaussianBlur(p = 1),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "horizon_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            A.RandomBrightness(p = 1),\n",
    "                            A.HorizontalFlip(p = 1),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "vertical_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            A.RandomBrightness(p = 1),\n",
    "                            A.VerticalFlip(p = 1),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            # A.RandomBrightness(p = 0.5),\n",
    "                            # A.HorizontalFlip(p = 0.5),\n",
    "                            # A.GaussianBlur(),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            # A.RandomBrightness(p = 0.5),\n",
    "                            # A.HorizontalFlip(p = 0.5),\n",
    "                            # A.GaussianBlur(),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "original_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "ro_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),max_pixel_value=255.0),\n",
    "                            # A.HorizontalFlip(p = 0.5),\n",
    "                            # A.RandomBrightness(),\n",
    "                            # A.GaussianBlur(),\n",
    "                            # A.RandomRotate90(),\n",
    "                            A.Rotate(),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "small_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            A.RandomBrightness(p = 1),\n",
    "                            A.GaussianBlur(p = 1),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "small_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "small_2_transform = A.Compose([\n",
    "                            A.Resize(260,260),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                            A.HorizontalFlip(p = 1),\n",
    "                            A.GaussianBlur(p = 1),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7259.700000000001\n"
     ]
    }
   ],
   "source": [
    "## 전체를 늘리고 나누기\n",
    "original_dataset = CustomDataset(df['img_path'], df['label'], original_transform)\n",
    "aug_dataset = CustomDataset(df['img_path'], df['label'], vertical_transform)\n",
    "aug_1_dataset = CustomDataset(df['img_path'], df['label'], horizon_transform)\n",
    "dataset = torch.utils.data.ConcatDataset((aug_dataset, aug_1_dataset, original_dataset))\n",
    "\n",
    "print(len(dataset) - len(dataset)*0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3111"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)-7260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [7260, 3111])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 32, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 자르고 넣기(val이랑 안겹치게...)\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values,train_transform)\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "\n",
    "original = CustomDataset(df['img_path'].values, df['label'].values, original_transform)\n",
    "# original = CustomDataset(df_0['img_path'].values, df_0['label'].values, original_transform)\n",
    "# original = CustomDataset(df_5['img_path'].values, df_5['label'].values, original_transform)\n",
    "\n",
    "# rotate = CustomDataset(df_1['img_path'].values, df_1['label'].values, ro_transform)\n",
    "# rotate_2 = CustomDataset(train['img_path'].values, train['label'].values, ro_transform)\n",
    "\n",
    "small = CustomDataset(df_2['img_path'].values, df_2['label'].values, small_transform)\n",
    "\n",
    "# small = CustomDataset(df_3['img_path'].values, df_3['label'].values, small_transform)\n",
    "# small_2 = CustomDataset(df_4['img_path'].values, df_4['label'].values, small_transform)\n",
    "# for i in range(2) :\n",
    "#     small += CustomDataset(df_3['img_path'].values, df_3['label'].values, small_transform)\n",
    "small = small + small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5385\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.ConcatDataset((train_dataset, original, small))\n",
    "print(train_dataset.__len__())\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = False, num_workers = 0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 32, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CoAtNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
    "    stride = 1 if downsample == False else 2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.GELU()\n",
    "    )\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn, norm):\n",
    "        super().__init__()\n",
    "        self.norm = norm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class SE(nn.Module):\n",
    "    def __init__(self, inp, oup, expansion=0.25):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(oup, int(inp * expansion), bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(int(inp * expansion), oup, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        stride = 1 if self.downsample == False else 2\n",
    "        hidden_dim = int(inp * expansion)\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        if expansion == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
    "                          1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                # down-sample in the first conv\n",
    "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
    "                          groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                SE(inp, hidden_dim),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        \n",
    "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            return self.proj(self.pool(x)) + self.conv(x)\n",
    "        else:\n",
    "            return x + self.conv(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == inp)\n",
    "\n",
    "        self.ih, self.iw = image_size\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        # parameter table of relative position bias\n",
    "        self.relative_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads))\n",
    "\n",
    "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))\n",
    "        coords = torch.flatten(torch.stack(coords), 1)\n",
    "        relative_coords = coords[:, :, None] - coords[:, None, :]\n",
    "\n",
    "        relative_coords[0] += self.ih - 1\n",
    "        relative_coords[1] += self.iw - 1\n",
    "        relative_coords[0] *= 2 * self.iw - 1\n",
    "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
    "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)\n",
    "        self.register_buffer(\"relative_index\", relative_index)\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, oup),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(\n",
    "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        # Use \"gather\" for more efficiency on GPUs\n",
    "        relative_bias = self.relative_bias_table.gather(\n",
    "            0, self.relative_index.repeat(1, self.heads))\n",
    "        relative_bias = rearrange(\n",
    "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw)\n",
    "        dots = dots + relative_bias\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(inp * 4)\n",
    "\n",
    "        self.ih, self.iw = image_size\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool1 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.pool2 = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
    "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
    "        else:\n",
    "            x = x + self.attn(x)\n",
    "        x = x + self.ff(x)\n",
    "        return x\n",
    "\n",
    "class CoAtNet(nn.Module):\n",
    "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'T', 'T']):\n",
    "        super().__init__()\n",
    "        ih, iw = image_size\n",
    "        block = {'C': MBConv, 'T': Transformer}\n",
    "\n",
    "        self.s0 = self._make_layer(\n",
    "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
    "        self.s1 = self._make_layer(\n",
    "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
    "        self.s2 = self._make_layer(\n",
    "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
    "        self.s3 = self._make_layer(\n",
    "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
    "        self.s4 = self._make_layer(\n",
    "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
    "\n",
    "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
    "        self.fc = nn.Linear(channels[-1], num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.s0(x)\n",
    "        x = self.s1(x)\n",
    "        x = self.s2(x)\n",
    "        x = self.s3(x)\n",
    "        x = self.s4(x)\n",
    "\n",
    "        x = self.pool(x).view(-1, x.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
    "        layers = nn.ModuleList([])\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                layers.append(block(inp, oup, image_size, downsample=True))\n",
    "            else:\n",
    "                layers.append(block(oup, oup, image_size))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def coatnet_0():\n",
    "    num_blocks = [2, 2, 3, 5, 2]            # L\n",
    "    channels = [64, 96, 192, 384, 768]      # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
    "\n",
    "def coatnet_1():\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
    "    channels = [64, 96, 192, 384, 768]      # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
    "\n",
    "def coatnet_2():\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
    "    channels = [128, 128, 256, 512, 1026]   # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
    "\n",
    "def coatnet_3():\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L\n",
    "    channels = [192, 192, 384, 768, 1536]   # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
    "\n",
    "def coatnet_4():\n",
    "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
    "    channels = [192, 192, 384, 768, 1536]   # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     img = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "#     net = coatnet_0()\n",
    "#     out = net(img)\n",
    "#     print(out.shape, count_parameters(net))\n",
    "\n",
    "#     net = coatnet_1()\n",
    "#     out = net(img)\n",
    "#     print(out.shape, count_parameters(net))\n",
    "\n",
    "#     net = coatnet_2()\n",
    "#     out = net(img)\n",
    "#     print(out.shape, count_parameters(net))\n",
    "\n",
    "#     net = coatnet_3()\n",
    "#     out = net(img)\n",
    "#     print(out.shape, count_parameters(net))\n",
    "\n",
    "#     net = coatnet_4()\n",
    "#     out = net(img)\n",
    "#     print(out.shape, count_parameters(net))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## efficientnet\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.efficientnet_b2(pretrained=True)\n",
    "        # self.backbone = timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
    "        self.classifier = nn.Linear(1000, 19)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = BaseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1000, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resnet\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        # self.backbone = timm.create_model('tf_efficientnetv2_s', pretrained=True)\n",
    "        self.classifier = nn.Linear(1000, 19)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = ResNetModel()\n",
    "model\n",
    "\n",
    "# class RESNET18(nn.Module):\n",
    "#     def __init__(self, out_channels):\n",
    "#         super(RESNET18, self).__init__()\n",
    "#         self.res18 = models.resnet18(pretrained=False)\n",
    "#         self.res18.fc = nn.Linear(in_features=self.res18.fc.in_features, out_features=out_channels)\n",
    "#         self.feature1 = nn.Sequential(*(list(self.res18.children())[0:8]))\n",
    "#         self.feature2 = nn.Sequential(list(self.res18.children())[8])\n",
    "#         self.feature3 = nn.Sequential(list(self.res18.children())[9])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         map = self.feature1(x)\n",
    "#         h1 = self.feature2(map)\n",
    "#         output = self.feature3(h1.reshape(h1.shape[0], -1))\n",
    "#         return output\n",
    "\n",
    "# model = RESNET18(19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mult model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelEfficientnet(\n",
       "  (efficientnet): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "              (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "              (1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "              (1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "              (1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=True)\n",
       "      (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (FC): Linear(in_features=1000, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiLabelEfficientnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelEfficientnet, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b2(pretrained=True)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.FC = nn.Linear(1000, 19)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.silu(self.efficientnet(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.sigmoid(self.FC(x))\n",
    "        return x\n",
    "\n",
    "model = MultiLabelEfficientnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# A memory-efficient implementation of Swish function\n",
    "class SwishImplementation(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_tensors[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "class MemoryEfficientSwish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return SwishImplementation.apply(x)\n",
    "        \n",
    "class MultiLabelEfficientnet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelEfficientnet2, self).__init__()\n",
    "        # self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "        self.fc = nn.Linear(1000, 19)\n",
    "\n",
    "\n",
    "        x = self._swish(self.conv2d(x))\n",
    "        x = self._swish(self.efficientnet(x))\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x\n",
    "\n",
    "model2 = MultiLabelEfficientnet2()\n",
    "model2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device) \n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "    \n",
    "    return _val_loss, _val_score, true_labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_start(model, optimizer, train_loader, val_loader, scheduler, num_epochs):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device) \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score, true_labels, preds = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_idx = epoch\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model, true_labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from lion_pytorch import Lion\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "# model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # torch.nn.BCELoss()\n",
    "criterion.to(device)\n",
    "\n",
    "# ## best\n",
    "# optimizer = Lion(model.parameters(), \n",
    "#                          lr = 3e-4,\n",
    "#                          weight_decay = 0.002,\n",
    "#                          betas = (0.9, 0.999))\n",
    "# lmbda = lambda epoch: 0.95\n",
    "# scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda = lmbda)\n",
    "\n",
    "## soso\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr = 3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "44040192\n",
      "36922880\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% |  5% |\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.empty_cache())\n",
    "print(torch.cuda.memory_reserved())\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(GPUtil.showUtilization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [2.10607] Val Loss : [2.12759] Val Weighted F1 Score : [0.82947]\n",
      "Epoch 1/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:22<00:00,  2.75it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [2.09914] Val Loss : [2.11447] Val Weighted F1 Score : [0.84776]\n",
      "Epoch 2/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:22<00:00,  2.75it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [2.09565] Val Loss : [2.11973] Val Weighted F1 Score : [0.84772]\n",
      "Epoch 3/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:22<00:00,  2.74it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [2.10150] Val Loss : [2.12037] Val Weighted F1 Score : [0.82865]\n",
      "Epoch 4/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [2.10006] Val Loss : [2.12979] Val Weighted F1 Score : [0.82237]\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.5000e-04.\n",
      "Epoch 5/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [2.08568] Val Loss : [2.11223] Val Weighted F1 Score : [0.87015]\n",
      "Epoch 6/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [2.07616] Val Loss : [2.10628] Val Weighted F1 Score : [0.85631]\n",
      "Epoch 7/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [2.07427] Val Loss : [2.10470] Val Weighted F1 Score : [0.87933]\n",
      "Epoch 8/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.71it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [2.07262] Val Loss : [2.10131] Val Weighted F1 Score : [0.88233]\n",
      "Epoch 9/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [2.06812] Val Loss : [2.09838] Val Weighted F1 Score : [0.88753]\n",
      "Epoch 10/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [2.06605] Val Loss : [2.09964] Val Weighted F1 Score : [0.88592]\n",
      "Epoch 11/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [2.06827] Val Loss : [2.09819] Val Weighted F1 Score : [0.89143]\n",
      "Epoch 12/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [2.06850] Val Loss : [2.10509] Val Weighted F1 Score : [0.88596]\n",
      "Epoch 13/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.73it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [2.06449] Val Loss : [2.09604] Val Weighted F1 Score : [0.88813]\n",
      "Epoch 14/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [2.06484] Val Loss : [2.09993] Val Weighted F1 Score : [0.87124]\n",
      "Epoch 00026: reducing learning rate of group 0 to 7.5000e-05.\n",
      "Epoch 15/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.73it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [2.06207] Val Loss : [2.09234] Val Weighted F1 Score : [0.90875]\n",
      "Epoch 16/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.72it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [2.05925] Val Loss : [2.08678] Val Weighted F1 Score : [0.91227]\n",
      "Epoch 17/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:23<00:00,  2.73it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [2.05802] Val Loss : [2.08743] Val Weighted F1 Score : [0.90743]\n",
      "Epoch 18/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [2.05721] Val Loss : [2.09329] Val Weighted F1 Score : [0.89898]\n",
      "Epoch 19/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.77it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [2.05666] Val Loss : [2.08491] Val Weighted F1 Score : [0.91403]\n",
      "Epoch 20/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [2.05721] Val Loss : [2.08857] Val Weighted F1 Score : [0.90827]\n",
      "Epoch 21/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:26<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [2.05644] Val Loss : [2.09076] Val Weighted F1 Score : [0.89901]\n",
      "Epoch 22/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [2.05576] Val Loss : [2.08671] Val Weighted F1 Score : [0.91399]\n",
      "Epoch 00034: reducing learning rate of group 0 to 3.7500e-05.\n",
      "Epoch 23/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [2.05368] Val Loss : [2.08580] Val Weighted F1 Score : [0.91819]\n",
      "Epoch 24/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [2.05321] Val Loss : [2.08282] Val Weighted F1 Score : [0.92110]\n",
      "Epoch 25/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [2.05317] Val Loss : [2.08353] Val Weighted F1 Score : [0.91949]\n",
      "Epoch 26/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [2.05286] Val Loss : [2.08460] Val Weighted F1 Score : [0.92106]\n",
      "Epoch 27/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [2.05218] Val Loss : [2.08521] Val Weighted F1 Score : [0.91959]\n",
      "Epoch 00039: reducing learning rate of group 0 to 1.8750e-05.\n",
      "Epoch 28/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [2.05226] Val Loss : [2.08568] Val Weighted F1 Score : [0.92193]\n",
      "Epoch 29/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [2.05112] Val Loss : [2.08188] Val Weighted F1 Score : [0.92397]\n",
      "Epoch 30/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Train Loss : [2.05090] Val Loss : [2.08534] Val Weighted F1 Score : [0.92544]\n",
      "Epoch 31/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Train Loss : [2.05064] Val Loss : [2.08148] Val Weighted F1 Score : [0.92796]\n",
      "Epoch 32/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Train Loss : [2.05076] Val Loss : [2.08376] Val Weighted F1 Score : [0.92303]\n",
      "Epoch 33/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Train Loss : [2.05057] Val Loss : [2.08445] Val Weighted F1 Score : [0.92496]\n",
      "Epoch 34/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Train Loss : [2.05016] Val Loss : [2.08317] Val Weighted F1 Score : [0.92437]\n",
      "Epoch 00046: reducing learning rate of group 0 to 9.3750e-06.\n",
      "Epoch 35/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Train Loss : [2.05052] Val Loss : [2.08222] Val Weighted F1 Score : [0.92720]\n",
      "Epoch 36/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Train Loss : [2.04989] Val Loss : [2.08204] Val Weighted F1 Score : [0.92431]\n",
      "Epoch 37/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Train Loss : [2.05066] Val Loss : [2.08268] Val Weighted F1 Score : [0.92521]\n",
      "Epoch 00049: reducing learning rate of group 0 to 4.6875e-06.\n",
      "Epoch 38/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.79it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Train Loss : [2.04994] Val Loss : [2.08026] Val Weighted F1 Score : [0.92653]\n",
      "Epoch 39/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Train Loss : [2.05016] Val Loss : [2.08439] Val Weighted F1 Score : [0.92375]\n",
      "Epoch 40/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Train Loss : [2.04950] Val Loss : [2.07890] Val Weighted F1 Score : [0.92446]\n",
      "Epoch 00052: reducing learning rate of group 0 to 2.3437e-06.\n",
      "Epoch 41/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Train Loss : [2.04945] Val Loss : [2.07898] Val Weighted F1 Score : [0.92482]\n",
      "Epoch 42/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.77it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Train Loss : [2.04947] Val Loss : [2.07996] Val Weighted F1 Score : [0.93122]\n",
      "Epoch 43/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Train Loss : [2.05033] Val Loss : [2.08049] Val Weighted F1 Score : [0.92844]\n",
      "Epoch 44/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Train Loss : [2.05002] Val Loss : [2.07884] Val Weighted F1 Score : [0.92794]\n",
      "Epoch 45/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Train Loss : [2.04968] Val Loss : [2.08169] Val Weighted F1 Score : [0.92707]\n",
      "Epoch 00057: reducing learning rate of group 0 to 1.1719e-06.\n",
      "Epoch 46/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Train Loss : [2.05014] Val Loss : [2.08233] Val Weighted F1 Score : [0.92554]\n",
      "Epoch 47/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:28<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Train Loss : [2.04940] Val Loss : [2.08081] Val Weighted F1 Score : [0.92518]\n",
      "Epoch 48/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Train Loss : [2.05026] Val Loss : [2.07920] Val Weighted F1 Score : [0.92671]\n",
      "Epoch 00060: reducing learning rate of group 0 to 5.8594e-07.\n",
      "Epoch 49/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:21<00:00,  2.78it/s]\n",
      "100%|██████████| 98/98 [00:27<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Train Loss : [2.04941] Val Loss : [2.08004] Val Weighted F1 Score : [0.92733]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer_model , true_labels, preds = train_start(model,\n",
    "                                               optimizer,\n",
    "                                               train_dataloader,\n",
    "                                               val_dataloader,\n",
    "                                               scheduler,\n",
    "                                               num_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    \"0\": \"가구수정\",          # a     \n",
    "    \"1\": \"걸레받이수정\",      # b\n",
    "    \"2\": \"곰팡이\",           # c  ....\n",
    "    \"3\": \"꼬임\",             # d\n",
    "    \"4\": \"녹오염\",           # e\n",
    "    \"5\": \"들뜸\",             # f\n",
    "    \"6\": \"면불량\",           # g ....\n",
    "    \"7\": \"몰딩수정\",         # h .....\n",
    "    \"8\": \"반점\",             # i\n",
    "    \"9\": \"석고수정\",         # j\n",
    "    \"10\": \"오염\",            # k\n",
    "    \"11\": \"오타공\",          # l  .....\n",
    "    \"12\": \"울음\",            # m\n",
    "    \"13\": \"이음부불량\",       # n\n",
    "    \"14\": \"창틀,문틀수정\",    # o\n",
    "    \"15\": \"터짐\",            # p  .....   \n",
    "    \"16\": \"틈새과다\",        # q\n",
    "    \"17\": \"피스\",            # r\n",
    "    \"18\": \"훼손\"             # s\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['가구수정','걸레받이수정','곰팡이','꼬임','녹오염','들뜸','면불량','몰딩수정','반점','석고수정','오염','오타공','울음','이음부불량','창틀,문틀수정','터짐','틈새과다','피스','훼손']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가구수정</th>\n",
       "      <th>걸레받이수정</th>\n",
       "      <th>곰팡이</th>\n",
       "      <th>꼬임</th>\n",
       "      <th>녹오염</th>\n",
       "      <th>들뜸</th>\n",
       "      <th>면불량</th>\n",
       "      <th>몰딩수정</th>\n",
       "      <th>반점</th>\n",
       "      <th>석고수정</th>\n",
       "      <th>오염</th>\n",
       "      <th>오타공</th>\n",
       "      <th>울음</th>\n",
       "      <th>이음부불량</th>\n",
       "      <th>창틀,문틀수정</th>\n",
       "      <th>터짐</th>\n",
       "      <th>틈새과다</th>\n",
       "      <th>피스</th>\n",
       "      <th>훼손</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>가구수정</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>걸레받이수정</th>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>곰팡이</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>꼬임</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>녹오염</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>들뜸</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>면불량</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>몰딩수정</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>반점</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>석고수정</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>오염</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>오타공</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>울음</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이음부불량</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>창틀,문틀수정</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>터짐</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>틈새과다</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>피스</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>훼손</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         가구수정  걸레받이수정  곰팡이   꼬임  녹오염  들뜸  면불량  몰딩수정  반점  석고수정   오염  오타공  울음   \n",
       "가구수정        0       0    0    1    0   4    0     0   0     0    0    0   0  \\\n",
       "걸레받이수정      0     258    0    0    0   0    0     0   0     0    1    0   0   \n",
       "곰팡이         0       5  111    0    0   0    0     0   0     0    2    0   0   \n",
       "꼬임          0       0    0  180    0   0    0     0   0     0    0    0   0   \n",
       "녹오염         0       0    0    0   11   0    0     0   0     0    0    0   0   \n",
       "들뜸          0       0    0    0    0  46    0     0   0     0    1    0   0   \n",
       "면불량         0       1    1    0    0   0   76     0   0     0    1    0   1   \n",
       "몰딩수정        0       0    0    0    0   0    1   128   0     0    0    0   0   \n",
       "반점          0       0    0    0    0   0    0     0   1     0    0    0   0   \n",
       "석고수정        0       0    0    0    0   0    0     0   0    40    0    1   0   \n",
       "오염          0       1    0    0    0   0    2     1   0     0  491    0   1   \n",
       "오타공         0       0    0    0    0   0    0     0   0     2    2  107   0   \n",
       "울음          0       0    0    0    0   0    0     0   0     0    3    0  15   \n",
       "이음부불량       0       0    0    0    0   0    0     0   0     0    0    0   0   \n",
       "창틀,문틀수정     0       1    0    4    0   0    0     5   0     0    2    0   0   \n",
       "터짐          0       1    0    0    0   0    0     1   0     0    1    0   0   \n",
       "틈새과다        0       0    0    1    0   0    0     0   0     0    1    0   0   \n",
       "피스          0       0    0    0    0   0    1     0   0     0    0    2   0   \n",
       "훼손          0       0    0    0    0   0    4     2   0     1   28    5   0   \n",
       "\n",
       "         이음부불량  창틀,문틀수정   터짐  틈새과다  피스    훼손  \n",
       "가구수정         0        0    0     0   0     2  \n",
       "걸레받이수정       0        0    0     0   0     2  \n",
       "곰팡이          0        0    0     0   0     0  \n",
       "꼬임           0        0    0     0   0     3  \n",
       "녹오염          0        0    0     0   0     0  \n",
       "들뜸           3        0    0     0   0     0  \n",
       "면불량          0        0    3     0   1    10  \n",
       "몰딩수정         0        0    0     0   1     2  \n",
       "반점           0        0    0     0   0     0  \n",
       "석고수정         0        0    0     0   1     4  \n",
       "오염           0        0    0     0   0    44  \n",
       "오타공          0        0    0     0   0     6  \n",
       "울음           0        0    0     0   0     2  \n",
       "이음부불량       10        0    0     0   0     2  \n",
       "창틀,문틀수정      0        0    0     0   1    12  \n",
       "터짐           0        0  142     0   0     7  \n",
       "틈새과다         0        0    0     0   0     3  \n",
       "피스           0        0    0     0  42     1  \n",
       "훼손           1        0    1     0   4  1245  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = pd.DataFrame(conf_matrix, index = names, columns = names )\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(con, annot = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_dataloader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttach as tta\n",
    "\n",
    "tta_transforms = tta.Compose(\n",
    "    [\n",
    "        # tta.Resize([260,260]),\n",
    "        # tta.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        tta.HorizontalFlip(),\n",
    "        tta.Multiply(factors=[0.9, 1, 1.1]),\n",
    "        # ToTensorV2()\n",
    "                      \n",
    "    ]\n",
    ")\n",
    "\n",
    "tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:10<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "preds2 = inference(tta_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:07<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_training = model.training\n",
    "model.train(mode=was_training);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.loc[submit['label'] == 'a', 'label'] = '가구수정'\n",
    "submit.loc[submit['label'] == 'b', 'label'] = '걸레받이수정'\n",
    "submit.loc[submit['label'] == 'c', 'label'] = '곰팡이'\n",
    "submit.loc[submit['label'] == 'd', 'label'] = '꼬임'\n",
    "submit.loc[submit['label'] == 'e', 'label'] = '녹오염'\n",
    "submit.loc[submit['label'] == 'f', 'label'] = '들뜸'\n",
    "submit.loc[submit['label'] == 'g', 'label'] = '면불량'\n",
    "submit.loc[submit['label'] == 'h', 'label'] = '몰딩수정'\n",
    "submit.loc[submit['label'] == 'i', 'label'] = '반점'\n",
    "submit.loc[submit['label'] == 'j', 'label'] = '석고수정'\n",
    "submit.loc[submit['label'] == 'k', 'label'] = '오염'\n",
    "submit.loc[submit['label'] == 'l', 'label'] = '오타공'\n",
    "submit.loc[submit['label'] == 'm', 'label'] = '울음'\n",
    "submit.loc[submit['label'] == 'n', 'label'] = '이음부불량'\n",
    "submit.loc[submit['label'] == 'o', 'label'] = '창틀,문틀수정'\n",
    "submit.loc[submit['label'] == 'p', 'label'] = '터짐'\n",
    "submit.loc[submit['label'] == 'q', 'label'] = '틈새과다'\n",
    "submit.loc[submit['label'] == 'r', 'label'] = '피스'\n",
    "submit.loc[submit['label'] == 's', 'label'] = '훼손'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "훼손        342\n",
       "오염        223\n",
       "터짐         38\n",
       "꼬임         38\n",
       "오타공        30\n",
       "면불량        27\n",
       "몰딩수정       16\n",
       "곰팡이        16\n",
       "걸레받이수정     15\n",
       "석고수정       12\n",
       "피스          9\n",
       "들뜸          8\n",
       "이음부불량       7\n",
       "녹오염         5\n",
       "울음          4\n",
       "반점          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./tta1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
